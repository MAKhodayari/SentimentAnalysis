{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df4937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from hazm import *\n",
    "from stopwords_guilannlp import *\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from string import punctuation\n",
    "import re\n",
    "from collections import Counter\n",
    "import math\n",
    "import xlrd\n",
    "import nltk\n",
    "import math\n",
    "normalizer = Normalizer()\n",
    "lemmatizer = Lemmatizer()\n",
    "stemmer = Stemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "843fa480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datatset():\n",
    "    dataset=pd.read_csv(\"ProjectData.csv\")\n",
    "    dataset=dataset[['comment','label']]\n",
    "    dataset=dataset[dataset['label'] != -2]\n",
    "    dataset=dataset.dropna()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c201caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersampl_data(dataset):\n",
    "    counts = dataset['label'].value_counts()\n",
    "    min_count = counts.min()\n",
    "    undersampled_df = pd.concat([\n",
    "        dataset[dataset['label'] == Label].sample(n=min_count)\n",
    "        for Label in counts.index\n",
    "    ])\n",
    "    \n",
    "    return undersampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dec5f1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=load_datatset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d36a528",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=undersampl_data(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dbde331",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = dataset ['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5126f94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    40149\n",
       "-1.0    17044\n",
       " 0.0     5627\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89aaf224",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>گردن بند خوبو قشنگیه خوبم جلوه میکنه و خودشو ن...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>به نظر من اصلا خوب نبود! به جاش با روغن زیتون ...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>من خریدم مبلم رو بی ریخت کرد و زود پاره شد</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>حتما پیشنهاد میکنم</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>در کل عالی</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62933</th>\n",
       "      <td>کواد کوپتر پرواز دادنش خیلی  لذت بخش هست به شر...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62934</th>\n",
       "      <td>سلاممن ازش خیلس راضی هستم شارژ 10000 واقعی خیل...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62935</th>\n",
       "      <td>این فیلتر رو تا بحال دو بار نصب و تعویض کردم. ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62936</th>\n",
       "      <td>ضد آفتاب مناسبی برای پوست چرب با رنگ‌خوب، البت...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62937</th>\n",
       "      <td>امروز سفارش به دستم رسید. ۳ تا از پایه‌های میز...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62820 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  label\n",
       "0      گردن بند خوبو قشنگیه خوبم جلوه میکنه و خودشو ن...    1.0\n",
       "1      به نظر من اصلا خوب نبود! به جاش با روغن زیتون ...   -1.0\n",
       "2             من خریدم مبلم رو بی ریخت کرد و زود پاره شد   -1.0\n",
       "3                                     حتما پیشنهاد میکنم    1.0\n",
       "4                                             در کل عالی    1.0\n",
       "...                                                  ...    ...\n",
       "62933  کواد کوپتر پرواز دادنش خیلی  لذت بخش هست به شر...    1.0\n",
       "62934  سلاممن ازش خیلس راضی هستم شارژ 10000 واقعی خیل...    1.0\n",
       "62935  این فیلتر رو تا بحال دو بار نصب و تعویض کردم. ...    1.0\n",
       "62936  ضد آفتاب مناسبی برای پوست چرب با رنگ‌خوب، البت...    1.0\n",
       "62937  امروز سفارش به دستم رسید. ۳ تا از پایه‌های میز...   -1.0\n",
       "\n",
       "[62820 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e031d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(comments):\n",
    "    stop_words = ['و', 'در', 'به', 'از', 'که', 'این', 'را', 'با', 'است', 'برای', 'آن', 'یک', 'خود', 'تا', 'کرد', 'بر', 'هم', 'نیز', 'گفت', 'می\\u200cشود', 'وی', 'شد', 'دارد', 'ما', 'اما', 'یا', 'شده', 'باید', 'هر', 'آنها', 'بود', 'او', 'دیگر', 'دو', 'مورد', 'می\\u200cکند', 'شود', 'کند', 'وجود', 'بین', 'پیش', 'شده_است', 'پس', 'نظر', 'اگر', 'همه', 'یکی', 'حال', 'هستند', 'من', 'کنند', 'نیست', 'باشد', 'چه', 'بی', 'می', 'بخش', 'می\\u200cکنند', 'همین', 'افزود', 'هایی', 'دارند', 'راه', 'همچنین', 'روی', 'داد', 'سه', 'داشت', 'چند', 'سوی', 'تنها', 'هیچ', 'میان', 'اینکه', 'شدن', 'بعد', 'جدید', 'ولی', 'حتی', 'کردن', 'برخی', 'کردند', 'می\\u200cدهد', 'اول', 'نه', 'کرده_است', 'نسبت', 'بیش', 'شما', 'چنین', 'طور', 'افراد', 'تمام', 'درباره', 'بار', 'بسیاری', 'می\\u200cتواند', 'کرده', 'چون', 'ندارد', 'دوم', 'بزرگ', 'طی', 'حدود', 'همان', 'بدون', 'البته', 'آنان', 'می\\u200cگوید', 'دیگری', 'خواهد_شد', 'کنیم', 'قابل', 'یعنی', 'رشد', 'می\\u200cتوان', 'وارد', 'کل', 'ویژه', 'قبل', 'براساس', 'نیاز', 'گذاری', 'هنوز', 'لازم', 'سازی', 'بوده_است', 'چرا', 'می\\u200cشوند', 'وقتی', 'گرفت', 'کم', 'جای', 'حالی', 'تغییر', 'پیدا', 'اکنون', 'تحت', 'باعث', 'مدت', 'فقط', 'تعداد', 'آیا', 'بیان', 'رو', 'شدند', 'عدم', 'کرده_اند', 'بودن', 'نوع', 'بلکه', 'جاری', 'دهد', 'برابر', 'مهم', 'بوده', 'اخیر', 'مربوط', 'امر', 'زیر', 'گیری', 'شاید', 'خصوص', 'آقای', 'اثر', 'کننده', 'بودند', 'فکر', 'کنار', 'اولین', 'سوم', 'سایر', 'کنید', 'ضمن', 'مانند', 'باز', 'می\\u200cگیرد', 'ممکن', 'حل', 'دارای', 'پی', 'مثل', 'می\\u200cرسد', 'اجرا', 'دور', 'منظور', 'کسی', 'موجب', 'طول', 'امکان', 'آنچه', 'تعیین', 'گفته', 'شوند', 'جمع', 'علاوه', 'گونه', 'تاکنون', 'رسید', 'ساله', 'گرفته', 'شده_اند', 'علت', 'چهار', 'داشته_باشد', 'خواهد_بود', 'طرف', 'تهیه', 'تبدیل', 'مناسب', 'زیرا', 'مشخص', 'می\\u200cتوانند', 'نزدیک', 'جریان', 'روند', 'بنابراین', 'می\\u200cدهند', 'یافت', 'نخستین', 'بالا', 'پنج', 'ریزی', 'چیزی', 'نخست', 'بیشتری', 'ترتیب', 'شده_بود', 'خاص', 'شروع', 'فرد', 'کامل', 'غیر', 'می\\u200cرود', 'دهند', 'آخرین', 'دادن', 'جدی', 'بهترین', 'شامل', 'گیرد', 'بخشی', 'باشند', 'تمامی', 'بهتر', 'داده_است', 'حد', 'نبود', 'کسانی', 'می\\u200cکرد', 'داریم', 'علیه', 'می\\u200cباشد', 'دانست', 'ناشی', 'داشتند', 'دهه', 'می\\u200cشد', 'ایشان', 'آنجا', 'گرفته_است', 'دچار', 'می\\u200cآید', 'لحاظ', 'آنکه', 'داده', 'بعضی', 'هستیم', 'اند', 'برداری', 'نباید', 'می\\u200cکنیم', 'نشست', 'سهم', 'همیشه', 'آمد', 'اش', 'وگو', 'می\\u200cکنم', 'حداقل', 'طبق', 'جا', 'خواهد_کرد', 'نوعی', 'چگونه', 'رفت', 'هنگام', 'فوق', 'روش', 'ندارند', 'سعی', 'بندی', 'شمار', 'کلی', 'کافی', 'مواجه', 'همچنان', 'سمت', 'کوچک', 'داشته_است', 'چیز', 'پشت', 'آورد', 'حالا', 'روبه', 'سال\\u200cهای', 'دادند', 'می\\u200cکردند', 'عهده', 'نیمه', 'جایی', 'دیگران', 'سی', 'بروز', 'یکدیگر', 'آمده_است', 'جز', 'کنم', 'سپس', 'کنندگان', 'خودش', 'همواره', 'یافته', 'شان', 'صرف', 'نمی\\u200cشود', 'رسیدن', 'چهارم', 'یابد', 'متر', 'ساز', 'داشته', 'کرده_بود', 'باره', 'نحوه', 'کردم', 'تو', 'شخصی', 'داشته_باشند', 'محسوب', 'پخش', 'کمی', 'متفاوت', 'سراسر', 'کاملا', 'داشتن', 'نظیر', 'آمده', 'گروهی', 'فردی', 'ع', 'همچون', 'خطر', 'خویش', 'کدام', 'دسته', 'سبب', 'عین', 'آوری', 'متاسفانه', 'بیرون', 'دار', 'ابتدا', 'شش', 'افرادی', 'می\\u200cگویند', 'سالهای', 'درون', 'نیستند', 'یافته_است', 'پر', 'خاطرنشان', 'گاه', 'جمعی', 'اغلب', 'دوباره', 'می\\u200cیابد', 'لذا', 'زاده', 'گردد', 'اینجا']\n",
    "    REPLACE_NO_SPACE = re.compile(\"[.`;:!\\'?,\\\"()\\[\\]،؛ًٌٍَُِّ]\")\n",
    "    REPLACE_NUMBER_ENGLISH = re.compile(\"[0-9A_Za-z۰-۹]\")\n",
    "    clean_comments = []\n",
    "    comments = [REPLACE_NO_SPACE.sub(\"\", line) for line in comments]\n",
    "    comments = [REPLACE_NUMBER_ENGLISH.sub(\"\", line) for line in comments]\n",
    "    for review in comments:\n",
    "        clean_comments.append(\n",
    "            ' '.join([word for word in review.split() \n",
    "                      if word not in stop_words])\n",
    "        )\n",
    "    return clean_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dcedef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    text = normalizer.normalize(text)\n",
    "    text = text.replace('.', ' ')\n",
    "    text = re.sub('\\s+', ' ', text).strip()\n",
    "    text = text.replace('\\u200c', ' ').replace('\\n', '').replace('\\r', '').replace('ي', 'ی').replace('ك', 'ک')\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a5e0fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_set(comments):\n",
    "    word_set = set()\n",
    "    for comment in comments:\n",
    "        for token in comment:\n",
    "            word_set.add(token)\n",
    "    return word_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bad60a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(comment):\n",
    "    stop_words = ['و', 'در', 'به', 'از', 'که', 'این', 'را', 'با', 'است', 'برای', 'آن', 'یک', 'خود', 'تا', 'کرد', 'بر', 'هم', 'نیز', 'گفت', 'می\\u200cشود', 'وی', 'شد', 'دارد', 'ما', 'اما', 'یا', 'شده', 'باید', 'هر', 'آنها', 'بود', 'او', 'دیگر', 'دو', 'مورد', 'می\\u200cکند', 'شود', 'کند', 'وجود', 'بین', 'پیش', 'شده_است', 'پس', 'نظر', 'اگر', 'همه', 'یکی', 'حال', 'هستند', 'من', 'کنند', 'نیست', 'باشد', 'چه', 'بی', 'می', 'بخش', 'می\\u200cکنند', 'همین', 'افزود', 'هایی', 'دارند', 'راه', 'همچنین', 'روی', 'داد', 'سه', 'داشت', 'چند', 'سوی', 'تنها', 'هیچ', 'میان', 'اینکه', 'شدن', 'بعد', 'جدید', 'ولی', 'حتی', 'کردن', 'برخی', 'کردند', 'می\\u200cدهد', 'اول', 'نه', 'کرده_است', 'نسبت', 'بیش', 'شما', 'چنین', 'طور', 'افراد', 'تمام', 'درباره', 'بار', 'بسیاری', 'می\\u200cتواند', 'کرده', 'چون', 'ندارد', 'دوم', 'بزرگ', 'طی', 'حدود', 'همان', 'بدون', 'البته', 'آنان', 'می\\u200cگوید', 'دیگری', 'خواهد_شد', 'کنیم', 'قابل', 'یعنی', 'رشد', 'می\\u200cتوان', 'وارد', 'کل', 'ویژه', 'قبل', 'براساس', 'نیاز', 'گذاری', 'هنوز', 'لازم', 'سازی', 'بوده_است', 'چرا', 'می\\u200cشوند', 'وقتی', 'گرفت', 'کم', 'جای', 'حالی', 'تغییر', 'پیدا', 'اکنون', 'تحت', 'باعث', 'مدت', 'فقط', 'تعداد', 'آیا', 'بیان', 'رو', 'شدند', 'عدم', 'کرده_اند', 'بودن', 'نوع', 'بلکه', 'جاری', 'دهد', 'برابر', 'مهم', 'بوده', 'اخیر', 'مربوط', 'امر', 'زیر', 'گیری', 'شاید', 'خصوص', 'آقای', 'اثر', 'کننده', 'بودند', 'فکر', 'کنار', 'اولین', 'سوم', 'سایر', 'کنید', 'ضمن', 'مانند', 'باز', 'می\\u200cگیرد', 'ممکن', 'حل', 'دارای', 'پی', 'مثل', 'می\\u200cرسد', 'اجرا', 'دور', 'منظور', 'کسی', 'موجب', 'طول', 'امکان', 'آنچه', 'تعیین', 'گفته', 'شوند', 'جمع', 'علاوه', 'گونه', 'تاکنون', 'رسید', 'ساله', 'گرفته', 'شده_اند', 'علت', 'چهار', 'داشته_باشد', 'خواهد_بود', 'طرف', 'تهیه', 'تبدیل', 'مناسب', 'زیرا', 'مشخص', 'می\\u200cتوانند', 'نزدیک', 'جریان', 'روند', 'بنابراین', 'می\\u200cدهند', 'یافت', 'نخستین', 'بالا', 'پنج', 'ریزی', 'چیزی', 'نخست', 'بیشتری', 'ترتیب', 'شده_بود', 'خاص', 'شروع', 'فرد', 'کامل', 'غیر', 'می\\u200cرود', 'دهند', 'آخرین', 'دادن', 'جدی', 'بهترین', 'شامل', 'گیرد', 'بخشی', 'باشند', 'تمامی', 'بهتر', 'داده_است', 'حد', 'نبود', 'کسانی', 'می\\u200cکرد', 'داریم', 'علیه', 'می\\u200cباشد', 'دانست', 'ناشی', 'داشتند', 'دهه', 'می\\u200cشد', 'ایشان', 'آنجا', 'گرفته_است', 'دچار', 'می\\u200cآید', 'لحاظ', 'آنکه', 'داده', 'بعضی', 'هستیم', 'اند', 'برداری', 'نباید', 'می\\u200cکنیم', 'نشست', 'سهم', 'همیشه', 'آمد', 'اش', 'وگو', 'می\\u200cکنم', 'حداقل', 'طبق', 'جا', 'خواهد_کرد', 'نوعی', 'چگونه', 'رفت', 'هنگام', 'فوق', 'روش', 'ندارند', 'سعی', 'بندی', 'شمار', 'کلی', 'کافی', 'مواجه', 'همچنان', 'سمت', 'کوچک', 'داشته_است', 'چیز', 'پشت', 'آورد', 'حالا', 'روبه', 'سال\\u200cهای', 'دادند', 'می\\u200cکردند', 'عهده', 'نیمه', 'جایی', 'دیگران', 'سی', 'بروز', 'یکدیگر', 'آمده_است', 'جز', 'کنم', 'سپس', 'کنندگان', 'خودش', 'همواره', 'یافته', 'شان', 'صرف', 'نمی\\u200cشود', 'رسیدن', 'چهارم', 'یابد', 'متر', 'ساز', 'داشته', 'کرده_بود', 'باره', 'نحوه', 'کردم', 'تو', 'شخصی', 'داشته_باشند', 'محسوب', 'پخش', 'کمی', 'متفاوت', 'سراسر', 'کاملا', 'داشتن', 'نظیر', 'آمده', 'گروهی', 'فردی', 'ع', 'همچون', 'خطر', 'خویش', 'کدام', 'دسته', 'سبب', 'عین', 'آوری', 'متاسفانه', 'بیرون', 'دار', 'ابتدا', 'شش', 'افرادی', 'می\\u200cگویند', 'سالهای', 'درون', 'نیستند', 'یافته_است', 'پر', 'خاطرنشان', 'گاه', 'جمعی', 'اغلب', 'دوباره', 'می\\u200cیابد', 'لذا', 'زاده', 'گردد', 'اینجا']\n",
    "    REPLACE_NO_SPACE = re.compile(\"[.`;:!\\'?,\\\"()\\[\\]،؛ًٌٍَُِّ]\")\n",
    "    REPLACE_NUMBER_ENGLISH = re.compile(\"[0-9A_Za-z۰-۹]\")\n",
    "    comment = [REPLACE_NO_SPACE.sub(\"\", line) for line in comment]\n",
    "    comment = [REPLACE_NUMBER_ENGLISH.sub(\"\", line) for line in comment]\n",
    "    comment = ''.join(c for c in comment if not c.isdigit())\n",
    "    comment = ''.join(c for c in comment if c not in punctuation)\n",
    "    comment = normalizer.normalize(comment)\n",
    "    tokens = word_tokenize(comment)\n",
    "    cleared_text = []\n",
    "    for word in tokens:\n",
    "        word = normalizer.normalize(word)\n",
    "#         word = stemmer.stem(word)\n",
    "        word = lemmatizer.lemmatize(word)\n",
    "          #word = re.sub(r'\\d+', '', word)\n",
    "        if word not in stop_words and len(word) > 1:\n",
    "                cleared_text.append(word)\n",
    "    return cleared_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c15d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=(dataset.iloc[:, :-1].values)\n",
    "y=dataset.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4f99bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=[]\n",
    "for i in range(len(X)):\n",
    "    tokens.append(preprocessing((X[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3524e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DF(tokens):\n",
    "    word_counts = Counter(word for feature in tokens for word in set(feature))\n",
    "    total_comments = len(tokens)\n",
    "    upper_threshold = total_comments * 0.8\n",
    "    lower_threshold = total_comments * 0.001\n",
    "    pruned_tokens_features = []\n",
    "    for feature in tokens:\n",
    "        pruned_feature = [word for word in feature if word_counts[word] < upper_threshold and word_counts[word] >= lower_threshold]\n",
    "        pruned_tokens_features.append(pruned_feature)\n",
    "\n",
    "    return pruned_tokens_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "517078fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=DF(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f20b5072",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fb2c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_Tf_Idf(tokens):\n",
    "    tf = []\n",
    "    for doc in tokens:\n",
    "        doc_tf = {}\n",
    "        for word in doc:\n",
    "            doc_tf[word] = doc.count(word) / len(doc)\n",
    "        tf.append(doc_tf)\n",
    "    idf = {}\n",
    "    for doc in tokens:\n",
    "        for word in set(doc):\n",
    "            if word in idf:\n",
    "                idf[word] += 1\n",
    "            else:\n",
    "                idf[word] = 1\n",
    "\n",
    "    num_docs = len(tokens)\n",
    "    for word in idf:\n",
    "        idf[word] = math.log((1 + num_docs) / (1 + idf[word])) + 1\n",
    "        \n",
    "    tfidf = []\n",
    "    for doc in tf:\n",
    "        doc_tfidf = {}\n",
    "        for word in doc:\n",
    "            doc_tfidf[word] = doc[word] * idf[word]\n",
    "        tfidf.append(doc_tfidf)\n",
    "\n",
    "    # Normalize the TF-IDF score for each word in each document\n",
    "    for i in range(len(tfidf)):\n",
    "        tfidf_values = list(tfidf[i].values())\n",
    "        norm = math.sqrt(sum(x**2 for x in tfidf_values))\n",
    "        for word in tfidf[i]:\n",
    "            tfidf[i][word] /= norm\n",
    "            \n",
    "    vocab = sorted(set(word for doc in tokens for word in doc))\n",
    "    matrix = [[doc.get(word, 0) for word in vocab] for doc in tfidf]\n",
    "    matrix = np.array(matrix)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1c6a8fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix=cal_Tf_Idf(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8217fb7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62820, 1782)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a327093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "X_new = SelectKBest(chi2, k=00).fit_transform(matrix,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d231ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix=X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8894ae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new,y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c476a00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7860553963705826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build the logistic regression model\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6b5c0b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2419,   17,  913],\n",
       "       [ 328,   39,  778],\n",
       "       [ 542,   34, 7494]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "45ff6dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7425978987583572\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Test the classifier\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f10f5e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2419,   17,  913],\n",
       "       [ 328,   39,  778],\n",
       "       [ 542,   34, 7494]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "80d3f89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7827921044253422\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear', decision_function_shape='ovr') # OVR stands for One-vs-Rest\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set labels\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "13b5feb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1782"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=create_word_set(temp)\n",
    "len(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
